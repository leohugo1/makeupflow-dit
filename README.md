    ğŸ’„ MakeupFlow-DiT: Latent Makeup Transfer with Flow Matching
Este repositÃ³rio contÃ©m a implementaÃ§Ã£o oficial do MakeupFlow-DiT, uma arquitetura de transferÃªncia de maquiagem baseada em Diffusion Transformers (DiT) e treinada via Flow Matching (I2I). O sistema utiliza um espaÃ§o latente comprimido para transferir estilos de maquiagem de uma imagem de referÃªncia para um rosto alvo em alta resoluÃ§Ã£o (512x512).

 ---
    ğŸš§ Status do Projeto: Treinamento Multietapa

O projeto utiliza um script unificado (train.py) para gerenciar as trÃªs fases crÃ­ticas de desenvolvimento:

**Fase 1: Treinamento do VAE** â€“ OtimizaÃ§Ã£o da reconstruÃ§Ã£o facial 512px usando CelebA-HQ com Perceptual Loss (LPIPS).

**Fase 2: Treinamento do StyleVit** â€“ ExtraÃ§Ã£o de embeddings de maquiagem via Vision Transformer e Triplet Margin Loss no dataset FFHQ-Makeup.

**Fase 3: Treinamento do DiT (Flow Matching)** â€“ Aprendizado da trajetÃ³ria linear entre o rosto limpo e maquiado.

 ---
    ğŸš€ Arquitetura TÃ©cnica
* **Diffusion Transformer (DiT)**: Implementado com blocos de Cross-Attention e ativaÃ§Ãµes SwiGLU (SwiGLUMP) para maior eficiÃªncia e estabilidade no aprendizado de fluxos.

* **StyleViT**: Um Vision Transformer que utiliza PEG (Positional Encoding Generator) para capturar texturas de maquiagem.

* **VAE (Variational Autoencoder)**: Estrutura robusta com ResnetBlocks e AttnBlocks. Utiliza um fator de escala latente de 0.18215 para compatibilidade com fluxos de difusÃ£o modernos.

---
    ğŸ› ï¸ Tecnologias e Bibliotecas

A stack tecnolÃ³gica foi selecionada para alta performance em GPUs como a RTX 3060:

**PyTorch 2.1+:** Suporte nativo a torch.compile e torch.amp (Mixed Precision).

**MLflow:** Rastreamento de experimentos e mÃ©tricas como SSIM e Loss em tempo real.

**LPIPS:** CÃ¡lculo de similaridade perceptual baseado em VGG para reconstruÃ§Ãµes de VAE ultra-nÃ­tidas.

**Hugging Face Datasets:** Pipelines de dados eficientes para FFHQ-Makeup e CelebA-HQ.

**Einops:** ManipulaÃ§Ã£o de tensores via einsum para operaÃ§Ãµes de patch e unpatch no DiT.

---



    ğŸ“¦ InstalaÃ§Ã£o
 ```
Bash
# Clone o repositÃ³rio
git clone https://github.com/leohugo1/makeupflow-dit.git
cd makeupflow-dit

# Instale as dependÃªncias otimizadas
pip install -r requirements.txt
```
    ğŸ‹ï¸ Como Executar
O treinamento Ã© controlado via argumentos de fase:
```
Bash
# Para treinar o VAE (Fase 1)
python train.py --phase train_vae

# Para treinar o Style Encoder (Fase 2)
python train.py --phase train_style_vit

# Para treinar o DiT via Flow Matching (Fase 3)
python train.py --phase train_dit
```
    InferÃªncia e Pesos
Os pesos prÃ©-treinados estarÃ£o disponÃ­veis no Hugging Face assim que as etapas de treinamento forem concluÃ­das: ğŸ”— Hugging Face: [MakeupFlow-DiT](https://huggingface.co/leonardohugo134/makeupflow-dit)